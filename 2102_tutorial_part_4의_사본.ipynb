{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ocRs35glrdbr"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leejungp2/imdb-inflearn/blob/main/2102_tutorial_part_4%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9-tYnsLrdY-"
      },
      "source": [
        "# Bag of Words Meets Bags of Popcorn\n",
        "\n",
        "* 캐글 경진대회 링크 : https://www.kaggle.com/c/word2vec-nlp-tutorial\n",
        "\n",
        "# 튜토리얼 파트 4 번외\n",
        "* tf-idf를 통해 벡터화 해보고 k_fold 를 사용해서 cross_validation 을 해본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xwb9NNgrdZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffaa6b3-e2e5-4c00-bb0e-926fcc6c87e5"
      },
      "source": [
        "import pandas as pd\n",
        "\"\"\"\n",
        "header = 0 은 파일의 첫 번째 줄에 열 이름이 있음을 나타내며\n",
        "delimiter = \\t 는 필드가 탭으로 구분되는 것을 의미한다.\n",
        "quoting = 3은 쌍따옴표를 무시하도록 한다.\n",
        "\"\"\"\n",
        "# QUOTE_MINIMAL (0), QUOTE_ALL (1),\n",
        "# QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
        "\n",
        "# 레이블인 sentiment 가 있는 학습 데이터\n",
        "# train = pd.read_csv('data/labeledTrainData.tsv',\n",
        "#                     header=0, delimiter='\\t', quoting=3)\n",
        "# # 레이블이 없는 테스트 데이터\n",
        "# test = pd.read_csv('data/testData.tsv',\n",
        "#                    header=0, delimiter='\\t', quoting=3)\n",
        "\n",
        "# 레이블인 sentiment 가 있는 학습 데이터\n",
        "train = pd.read_csv('https://github.com/corazzon/KaggleStruggle/raw/master/word2vec-nlp-tutorial/data/labeledTrainData.tsv', delimiter='\\t', quoting=3)\n",
        "# 레이블이 없는 테스트 데이터\n",
        "test = pd.read_csv('https://github.com/corazzon/KaggleStruggle/raw/master/word2vec-nlp-tutorial/data/testData.tsv', delimiter='\\t', quoting=3)\n",
        "\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 3)\n",
            "(25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6FJuSMqrdZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3217561-a8c4-4d73-cfbd-01af70aa2634"
      },
      "source": [
        "# 긍정과 부정 리뷰가 어떻게 들어있는지 카운트 해본다.\n",
        "# 긍정과 부정리뷰가 각각 동일하게 12,500개씩 들어있다.\n",
        "train['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12500\n",
              "0    12500\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1SwN8jjrdZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c152589-28ae-479f-f47a-a7c45635d619"
      },
      "source": [
        "# 학습데이터에는 sentiment 데이터가 있다.\n",
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0    id        25000 non-null  object\n",
            " 1   sentiment  25000 non-null  int64 \n",
            " 2   review     25000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 586.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq2wbiiordZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29f3574-8e0f-4541-a58b-95316e0a2e78"
      },
      "source": [
        "# 테스트 데이터에는 sentiment가 없으며 이 sentiment를 예측하는 게 이 경진대회의 미션이다.\n",
        "test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      25000 non-null  object\n",
            " 1   review  25000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 390.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEjPXIOcsKE_",
        "outputId": "32b2d130-38c0-442a-a47b-f8b9c32404ae"
      },
      "source": [
        "# 전처리 모듈 가져오기\n",
        "!wget https://github.com/corazzon/KaggleStruggle/raw/master/word2vec-nlp-tutorial/KaggleWord2VecUtility.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-18 00:37:26--  https://github.com/corazzon/KaggleStruggle/raw/master/word2vec-nlp-tutorial/KaggleWord2VecUtility.py\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/corazzon/KaggleStruggle/master/word2vec-nlp-tutorial/KaggleWord2VecUtility.py [following]\n",
            "--2021-05-18 00:37:26--  https://raw.githubusercontent.com/corazzon/KaggleStruggle/master/word2vec-nlp-tutorial/KaggleWord2VecUtility.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3250 (3.2K) [text/plain]\n",
            "Saving to: ‘KaggleWord2VecUtility.py’\n",
            "\n",
            "KaggleWord2VecUtili 100%[===================>]   3.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-18 00:37:26 (43.8 MB/s) - ‘KaggleWord2VecUtility.py’ saved [3250/3250]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klu678OTs36Q",
        "outputId": "e7152aa4-c80d-451c-fba0-dd3a7cd1d436"
      },
      "source": [
        "# 필요도구 다운로드\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O87PGgGIrdZQ"
      },
      "source": [
        "# 데이터 전처리는 튜토리얼 파트1~4까지 공통으로 사용되기 때문에 별도의 파이썬 파일로 분리했다.\n",
        "# 그리고 캐글에 있는 코드를 병렬처리하도록 멀티프로세싱 코드를 추가했다.\n",
        "# 하지만 여기에서는 멀티프로세싱 코드만 임포트해서 사용하고 전처리는 태그만 제거해주도록 한다.\n",
        "# 그리고 WordNetLemmatizer로 레마타이징 한다.\n",
        "# 음소표기법(lemmatization)은 튜토리얼 파트1에 설명 되어 있고 다음 링크에 있다.\n",
        "# https://github.com/corazzon/KaggleStruggle/blob/master/word2vec-nlp-tutorial/tutorial-part-1.ipynb\n",
        "from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def review_to_words( raw_review ):\n",
        "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
        "    review_text = wordnet_lemmatizer.lemmatize(review_text)\n",
        "    return review_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTWj2183rdZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5488e4-1ef5-4d6a-8b12-a15e0a24e81c"
      },
      "source": [
        "# 학습데이터를 전처리 한다.\n",
        "%time train['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
        "    train['review'], review_to_words, workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 220 ms, sys: 213 ms, total: 434 ms\n",
            "Wall time: 10.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOhVl5HRrdZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2bb51f-c2ed-414b-84b2-cc3f66a943d7"
      },
      "source": [
        "# 학습데이터와 동일하게 테스트 데이터에 대해서도 전처리 한다.\n",
        "%time test['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
        "    test['review'], review_to_words, workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 168 ms, sys: 174 ms, total: 342 ms\n",
            "Wall time: 9.98 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj1liHW8rdZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3466bbf-1cdd-48cf-c922-454243604206"
      },
      "source": [
        "# 전처리한 학습 데이터 10개만을 불러와서 본다.\n",
        "train['review_clean'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    \"With all this stuff going down at the moment ...\n",
              "1    \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2    \"The film starts with a manager (Nicholas Bell...\n",
              "3    \"It must be assumed that those who praised thi...\n",
              "4    \"Superbly trashy and wondrously unpretentious ...\n",
              "5    \"I dont know why people think this is such a b...\n",
              "6    \"This movie could have been very good, but com...\n",
              "7    \"I watched this video at a friend's house. I'm...\n",
              "8    \"A friend of mine bought this film for £1, and...\n",
              "9    \"This movie is full of references. Like \\\"Mad ...\n",
              "Name: review_clean, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZSJ5R0WrdZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3d8254-2358-4e14-b942-ec220257ca89"
      },
      "source": [
        "# 전처리한 테스트 데이터 10개만을 불러와서 본다.\n",
        "test['review_clean'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    \"Naturally in a film who's main themes are of ...\n",
              "1    \"This movie is a disaster within a disaster fi...\n",
              "2    \"All in all, this is a movie for kids. We saw ...\n",
              "3    \"Afraid of the Dark left me with the impressio...\n",
              "4    \"A very accurate depiction of small time mob l...\n",
              "5    \"...as valuable as King Tut's tomb! (OK, maybe...\n",
              "6    \"This has to be one of the biggest misfires ev...\n",
              "7    \"This is one of those movies I watched, and wo...\n",
              "8    \"The worst movie i've seen in years (and i've ...\n",
              "9    \"Five medical students (Kevin Bacon, David Lab...\n",
              "Name: review_clean, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5zE9qCirdZT"
      },
      "source": [
        "# X_train과 X_test에 리뷰 데이터를 담아주고 이 데이터를 TF-IDF를 통해 임베딩(벡터화)해본다.\n",
        "X_train = train['review_clean']\n",
        "X_test = test['review_clean']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDVURQgLrdZT"
      },
      "source": [
        "## TF-IDF\n",
        "TF(단어 빈도, term frequency)는 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값으로, 이 값이 높을수록 문서에서 중요하다고 생각할 수 있다. 하지만 단어 자체가 문서군 내에서 자주 사용되는 경우, 이것은 그 단어가 흔하게 등장한다는 것을 의미한다. 이것을 DF(문서 빈도, document frequency)라고 하며, 이 값의 역수를 IDF(역문서 빈도, inverse document frequency)라고 한다. TF-IDF는 TF와 IDF를 곱한 값이다.\n",
        "\n",
        "IDF 값은 문서군의 성격에 따라 결정된다. 예를 들어 '원자'라는 낱말은 일반적인 문서들 사이에서는 잘 나오지 않기 때문에 IDF 값이 높아지고 문서의 핵심어가 될 수 있지만, 원자에 대한 문서를 모아놓은 문서군의 경우 이 낱말은 상투어가 되어 각 문서들을 세분화하여 구분할 수 있는 다른 낱말들이 높은 가중치를 얻게 된다.\n",
        "\n",
        "역문서 빈도(IDF)는 한 단어가 문서 집합 전체에서 얼마나 공통적으로 나타나는지를 나타내는 값이다. 전체 문서의 수를 해당 단어를 포함한 문서의 수로 나눈 뒤 로그를 취하여 얻을 수 있다.\n",
        "\n",
        "* 출처 : [TF-IDF - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/TF-IDF)\n",
        "\n",
        "\\begin{equation*}\n",
        "\\text{tfidf}(w, d) = \\text{tf} \\times (\\log\\big(\\frac{N + 1}{N_w + 1}\\big) + 1)\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "* 싸이킷런 공식문서 : [4.2. Feature extraction — scikit-learn 0.19.1 documentation](http://scikit-learn.org/stable/modules/feature_extraction.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm4WlfIJrdZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19b5334-bb0b-4acf-ebfe-9051ef83db80"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.corpus import words\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer = 'word',\n",
        "                             lowercase = True,\n",
        "                             tokenizer = None,\n",
        "                             preprocessor = None,\n",
        "                             stop_words = 'english',\n",
        "                             min_df = 2, # 토큰이 나타날 최소 문서 개수로 오타나 자주 나오지 않는 특수한 전문용어 제거에 좋다.\n",
        "                             ngram_range=(1, 3),\n",
        "                             vocabulary = set(words.words()), # nltk의 words를 사용하거나 문서 자체의 사전을 만들거나 선택한다.\n",
        "                             max_features = 90000\n",
        "                            )\n",
        "vectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=90000, min_df=2,\n",
              "                ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None,\n",
              "                vocabulary={'A', 'Aani', 'Aaron', 'Aaronic', 'Aaronical',\n",
              "                            'Aaronite', 'Aaronitic', 'Aaru', 'Ab', 'Ababdeh',\n",
              "                            'Ababua', 'Abadite', 'Abama', 'Abanic', 'Abantes',\n",
              "                            'Abarambo', 'Abaris', 'Abasgi', 'Abassin', 'Abatua',\n",
              "                            'Abba', 'Abbadide', 'Abbasside', 'Abbie', 'Abby',\n",
              "                            'Abderian', 'Abderite', 'Abdiel', 'Abdominales',\n",
              "                            'Abe', ...})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNq_RJR8rdZU"
      },
      "source": [
        "### TfidfTransformer()\n",
        "* norm='l2' 각 문서의 피처 벡터를 어떻게 벡터 정규화 할지 정한다.\n",
        "    - L2 : 벡터의 각 원소의 제곱의 합이 1이 되도록 만드는 것이고 기본 값\n",
        "    - L1 : 벡터의 각 원소의 절댓값의 합이 1이 되도록 크기를 조절\n",
        "* smooth_idf=False\n",
        "    - 피처를 만들 때 0으로 나오는 항목에 대해 작은 값을 더해서(스무딩을 해서) 피처를 만들지 아니면 그냥 생성할지를 결정\n",
        "* sublinear_tf=False\n",
        "* use_idf=True\n",
        "    - TF-IDF를 사용해 피처를 만들 것인지 아니면 단어 빈도 자체를 사용할 것인지 여부"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcLU2UArdZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f77f3f5-fa84-4209-e335-7057681e6b3e"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vect', vectorizer),\n",
        "    ('tfidf', TfidfTransformer(smooth_idf = False)),\n",
        "])\n",
        "pipeline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=90000, min_df=2,\n",
              "                                 ngram_range=(1, 3), preprocessor=None,\n",
              "                                 stop_words='english', strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None,\n",
              "                                 vocabula...\n",
              "                                             'Aaronical', 'Aaronite',\n",
              "                                             'Aaronitic', 'Aaru', 'Ab',\n",
              "                                             'Ababdeh', 'Ababua', 'Abadite',\n",
              "                                             'Abama', 'Abanic', 'Abantes',\n",
              "                                             'Abarambo', 'Abaris', 'Abasgi',\n",
              "                                             'Abassin', 'Abatua', 'Abba',\n",
              "                                             'Abbadide', 'Abbasside', 'Abbie',\n",
              "                                             'Abby', 'Abderian', 'Abderite',\n",
              "                                             'Abdiel', 'Abdominales', 'Abe', ...})),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=False,\n",
              "                                  sublinear_tf=False, use_idf=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VBg0dH4lrdZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645273bc-45c3-41c0-c690-6048e5d7eaba"
      },
      "source": [
        "%time X_train_tfidf_vector = pipeline.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.66 s, sys: 82.5 ms, total: 8.75 s\n",
            "Wall time: 8.78 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:1466: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  idf = np.log(n_samples / df) + 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3SENim7rdZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc3aed7-cd74-48b9-e6b5-09044dd50d84"
      },
      "source": [
        "vocab = vectorizer.get_feature_names()\n",
        "print(len(vocab))\n",
        "vocab[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'Aani',\n",
              " 'Aaron',\n",
              " 'Aaronic',\n",
              " 'Aaronical',\n",
              " 'Aaronite',\n",
              " 'Aaronitic',\n",
              " 'Aaru',\n",
              " 'Ab',\n",
              " 'Ababdeh']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgkAWe-rrdZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e57fb0d-d26c-4f88-9f12-217d1e539d9b"
      },
      "source": [
        "%time X_test_tfidf_vector = pipeline.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.15 s, sys: 64.3 ms, total: 9.22 s\n",
            "Wall time: 9.23 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:1466: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  idf = np.log(n_samples / df) + 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rZ_9L6yrdaJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "38995ec3-27fc-4add-e74b-ff22af883a9f"
      },
      "source": [
        "import numpy as np\n",
        "dist = np.sum(X_train_tfidf_vector, axis=0)\n",
        "\n",
        "for tag, count in zip(vocab, dist):\n",
        "    print(count, tag)\n",
        "\n",
        "pd.DataFrame(dist, columns=vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]] A\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>Aani</th>\n",
              "      <th>Aaron</th>\n",
              "      <th>Aaronic</th>\n",
              "      <th>Aaronical</th>\n",
              "      <th>Aaronite</th>\n",
              "      <th>Aaronitic</th>\n",
              "      <th>Aaru</th>\n",
              "      <th>Ab</th>\n",
              "      <th>Ababdeh</th>\n",
              "      <th>Ababua</th>\n",
              "      <th>Abadite</th>\n",
              "      <th>Abama</th>\n",
              "      <th>Abanic</th>\n",
              "      <th>Abantes</th>\n",
              "      <th>Abarambo</th>\n",
              "      <th>Abaris</th>\n",
              "      <th>Abasgi</th>\n",
              "      <th>Abassin</th>\n",
              "      <th>Abatua</th>\n",
              "      <th>Abba</th>\n",
              "      <th>Abbadide</th>\n",
              "      <th>Abbasside</th>\n",
              "      <th>Abbie</th>\n",
              "      <th>Abby</th>\n",
              "      <th>Abderian</th>\n",
              "      <th>Abderite</th>\n",
              "      <th>Abdiel</th>\n",
              "      <th>Abdominales</th>\n",
              "      <th>Abe</th>\n",
              "      <th>Abel</th>\n",
              "      <th>Abelia</th>\n",
              "      <th>Abelian</th>\n",
              "      <th>Abelicea</th>\n",
              "      <th>Abelite</th>\n",
              "      <th>Abelmoschus</th>\n",
              "      <th>Abelonian</th>\n",
              "      <th>Abencerrages</th>\n",
              "      <th>Aberdeen</th>\n",
              "      <th>Aberdonian</th>\n",
              "      <th>...</th>\n",
              "      <th>zymic</th>\n",
              "      <th>zymin</th>\n",
              "      <th>zymite</th>\n",
              "      <th>zymogen</th>\n",
              "      <th>zymogene</th>\n",
              "      <th>zymogenesis</th>\n",
              "      <th>zymogenic</th>\n",
              "      <th>zymogenous</th>\n",
              "      <th>zymoid</th>\n",
              "      <th>zymologic</th>\n",
              "      <th>zymological</th>\n",
              "      <th>zymologist</th>\n",
              "      <th>zymology</th>\n",
              "      <th>zymolyis</th>\n",
              "      <th>zymolysis</th>\n",
              "      <th>zymolytic</th>\n",
              "      <th>zymome</th>\n",
              "      <th>zymometer</th>\n",
              "      <th>zymomin</th>\n",
              "      <th>zymophore</th>\n",
              "      <th>zymophoric</th>\n",
              "      <th>zymophosphate</th>\n",
              "      <th>zymophyte</th>\n",
              "      <th>zymoplastic</th>\n",
              "      <th>zymoscope</th>\n",
              "      <th>zymosimeter</th>\n",
              "      <th>zymosis</th>\n",
              "      <th>zymosterol</th>\n",
              "      <th>zymosthenic</th>\n",
              "      <th>zymotechnic</th>\n",
              "      <th>zymotechnical</th>\n",
              "      <th>zymotechnics</th>\n",
              "      <th>zymotechny</th>\n",
              "      <th>zymotic</th>\n",
              "      <th>zymotically</th>\n",
              "      <th>zymotize</th>\n",
              "      <th>zymotoxic</th>\n",
              "      <th>zymurgy</th>\n",
              "      <th>zythem</th>\n",
              "      <th>zythum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 235892 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     A  Aani  Aaron  Aaronic  ...  zymotoxic  zymurgy  zythem  zythum\n",
              "0  0.0   0.0    0.0      0.0  ...        0.0      0.0     0.0     0.0\n",
              "\n",
              "[1 rows x 235892 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZteuK5RrdaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4716c5-e242-45fb-90d3-fdb48142b077"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 랜덤포레스트 분류기를 사용\n",
        "forest = RandomForestClassifier(\n",
        "    n_estimators = 100, n_jobs = -1, random_state=2018)\n",
        "forest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=2018, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnGkDFA0rdaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd8a61b-c84f-4930-e4ef-15d38a4c5120"
      },
      "source": [
        "%time forest = forest.fit(X_train_tfidf_vector, train['sentiment'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 59s, sys: 477 ms, total: 4min\n",
            "Wall time: 2min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6PPBkxCrdaQ"
      },
      "source": [
        "### Cross Validation 교차 검증\n",
        "* 일반화 성능을 측정하기 위해 데이터를 여러 번 반복해서 나누고 여러 모델을 학습한다.\n",
        "![image.png](https://www.researchgate.net/profile/Halil_Bisgin/publication/228403467/figure/fig2/AS:302039595798534@1449023259454/Figure-4-k-fold-cross-validation-scheme-example.png)\n",
        "이미지 출처 : https://www.researchgate.net/figure/228403467_fig2_Figure-4-k-fold-cross-validation-scheme-example\n",
        "\n",
        "\n",
        "* KFold 교차검증\n",
        "    * 데이터를 폴드라 부르는 비슷한 크기의 부분집합(n_splits)으로 나누고 각각의 폴드 정확도를 측정한다.\n",
        "    * 첫 번째 폴드를 테스트 세트로 사용하고 나머지 폴드를 훈련세트로 사용하여 학습한다.\n",
        "    * 나머지 훈련세트로 만들어진 세트의 정확도를 첫 번째 폴드로 평가한다.\n",
        "    * 다음은 두 번째 폴드가 테스트 세트가 되고 나머지 폴드의 훈련세트를 두 번째 폴드로 정확도를 측정한다.\n",
        "    * 이 과정을 마지막 폴드까지 반복한다.\n",
        "    * 이렇게 훈련세트와 테스트세트로 나누는 N개의 분할마다 정확도를 측정하여 평균 값을 낸게 정확도가 된다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_3R6oMdrdaQ"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi_Yq5mprdaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e99047-58bf-433f-dca5-ee3ff6495a5c"
      },
      "source": [
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
        "\n",
        "%time score = np.mean(cross_val_score(\\\n",
        "    forest, X_train_tfidf_vector, \\\n",
        "    train['sentiment'], cv=k_fold, scoring='roc_auc', n_jobs=-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.58 s, sys: 358 ms, total: 2.94 s\n",
            "Wall time: 8min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMf8MVB6rdax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e17c2f82-9102-4881-d50f-d3796ba8b544"
      },
      "source": [
        "# 0.92149\n",
        "'{:,.5f}'.format(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.92051'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ8JI2WHrdbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d4c74b-011f-4387-e83a-35ca5b86c7d2"
      },
      "source": [
        "%time result = forest.predict(X_test_tfidf_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.45 s, sys: 34.8 ms, total: 3.49 s\n",
            "Wall time: 1.92 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErV6FQ-vrdbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e800a5b0-2666-455a-89f0-7ea280bc13d0"
      },
      "source": [
        "result[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsX7ArzurdbU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e66d8600-597b-425b-e38e-a4312c4527a8"
      },
      "source": [
        "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\n",
        "output.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"12311_10\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"8348_2\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"5828_4\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7186_2\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"12128_7\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment\n",
              "0  \"12311_10\"          1\n",
              "1    \"8348_2\"          0\n",
              "2    \"5828_4\"          0\n",
              "3    \"7186_2\"          0\n",
              "4   \"12128_7\"          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb79hnTcrdbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3356fb6-4be8-4608-e39a-991a83b4a39d"
      },
      "source": [
        "output_sentiment = output['sentiment'].value_counts()\n",
        "print(output_sentiment[0] - output_sentiment[1])\n",
        "output_sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12689\n",
              "0    12311\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clomql0cY7sZ"
      },
      "source": [
        "# data 폴더가 없다면 생성합니다.\n",
        "%mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv2bauaFrdbY"
      },
      "source": [
        "output.to_csv('data/tutorial_4_tfidf_{0:.5f}.csv'.format(score), index=False, quoting=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MmPmzcFrdbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bb5da9-1e78-451c-f073-7d0b29413be9"
      },
      "source": [
        "# 그런데 점수가 너무 낮게 나옴\n",
        "# local 0.92149 kaggle 0.84392\n",
        "# stop_words = 'english' vocabulary = set(words.words()), smooth_idf = False\n",
        "468/578"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8096885813148789"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YexvjhlurdbZ"
      },
      "source": [
        "## XGBoost: A Scalable Tree Boosting System\n",
        "* 2015년 캐글 블로그에 xgboost를 사용하여 17건의 우승 솔루션이 공유됨 :  [Dato Winners’ Interview: 1st place, Mad Professors | No Free Hunch](http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/)\n",
        "* 2016년 논문이 등록 됨 : [XGBoostArxiv.pdf](http://dmlc.cs.washington.edu/data/pdf/XGBoostArxiv.pdf)\n",
        "* 공식문서 : [XGBoost Documents](https://xgboost.readthedocs.io/en/latest/)\n",
        "* 분산형 그래디언트 부스팅 알고리즘\n",
        "* 부스팅 알고리즘은?\n",
        "    * 부스팅 알고리즘은 약한 예측모형들을 결합하여 강한 예측모형을 만드는 알고리즘\n",
        "    * 배깅과 유사하게 초기 샘플데이터로 다수의 분류기를 만들지만 배깅과 다르게 순차적이다.\n",
        "    * 랜덤포레스트의 배깅과는 다르게 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듦\n",
        "    * 결정트리(Decision Tree) 알고리즘의 연장선에 있음\n",
        "    * 여러 개의 결정트리를 묶어 강력한 모델을 만드는 앙상블 방법\n",
        "    * 분류와 회귀에 사용할 수 있음\n",
        "    * 무작위성이 없으며 강력한 사전 가지치기를 사용\n",
        "    * 참고 이미지 : http://www.birc.co.kr/2017/02/06/%EC%95%99%EC%83%81%EB%B8%94ensemble-%EB%B6%80%EC%8A%A4%ED%8C%85boosting/\n",
        "    * 배깅과 부스팅의 차이점은 udacity에서 설명한 영상이 가장 도움이 되었음\n",
        "        * 배깅 : https://www.youtube.com/watch?v=2Mg8QD0F1dQ\n",
        "        * 부스팅 : https://www.youtube.com/watch?v=GM3CDQfQ4sw\n",
        "* 타이타닉 경진대회에 사용 예제가 있음 [XGBoost example (Python) | Kaggle](https://www.kaggle.com/datacanary/xgboost-example-python/)\n",
        "\n",
        "\n",
        "## [Mac OSX에서 XGBoost 설치하기](http://corazzon.github.io/xgboost-install-mac-osx)\n",
        "* http://corazzon.github.io/xgboost-install-mac-osx\n",
        "\n",
        "* [A Gentle Introduction to XGBoost for Applied Machine Learning - Machine Learning Mastery](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/)\n",
        "\n",
        "* https://speakerdeck.com/datasciencela/tianqi-chen-xgboost-overview-and-latest-news-la-meetup-talk\n",
        "\n",
        "* datacamp의 XGboost 온라인 강의 : [Extreme Gradient Boosting with XGBoost](https://www.datacamp.com/courses/extreme-gradient-boosting-with-xgboost)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlMTqgdxrdbj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0247bf8c-25b1-4e97-8640-fa7a864aa20d"
      },
      "source": [
        "\"\"\"강의에 사용한 아래 코드 대신 하단의 코드를 사용해 주세요.\"\"\"\n",
        "# import xgboost as xgb\n",
        "\n",
        "# 멀티프로세싱은 nthread 였는데 n_jobs로 변경되었다고 한다.\n",
        "# 설치 된 xgboost버전에 따라 파라메터가 다를 수 있으니\n",
        "# 이 코드를 돌리고 터미널에서 $ top -o cpu 로 CPU자원을 100%넘게 사용하고 있는지 확인해 본다.\n",
        "# params = {\n",
        "#     'booster': 'gblinear',\n",
        "#     'objective': 'multi:softmax',\n",
        "#     'eval_metric': 'merror',\n",
        "#     'eta' : 0.02,\n",
        "#     'lambda': 2.0,\n",
        "#     'alpha': 1.0,\n",
        "#     'lambda_bias': 6.0,\n",
        "#     'num_class': 5,\n",
        "#     'n_jobs' : 4,\n",
        "#     'silent': 1,\n",
        "# }\n",
        "\n",
        "# dtrain = xgb.DMatrix(X_train_tfidf_vector, label=train['sentiment'])\n",
        "# %time booster = xgb.train(params, dtrain, num_boost_round=100)\n",
        "# dtest = xgb.DMatrix(X_test_tfidf_vector)\n",
        "\n",
        "# result = booster.predict(dtest)\n",
        "\n",
        "# print(result.shape)\n",
        "# result[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'강의에 사용한 아래 코드 대신 하단의 코드를 사용해 주세요.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXq0Y0PPYZ0e"
      },
      "source": [
        "# XGBClassifier 불러오기\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=100,learning_rate=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bob8171jZZjM"
      },
      "source": [
        "# 정답 레이블을 y_train 변수에 담아 사용합니다.\n",
        "y_train = train['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4tkZohUYVkq",
        "outputId": "1155262c-e6da-4174-b1f3-4addc074a118"
      },
      "source": [
        "# XGBClassifier 로 학습합니다.\n",
        "xgb.fit(X_test_tfidf_vector, y_train, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czdTOMih88Om",
        "outputId": "de832871-f621-4b2d-cb9d-1ae0cc5cf302"
      },
      "source": [
        "# predict로 예측합니다.\n",
        "result = xgb.predict(X_test_tfidf_vector)\n",
        "result[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHIlfZwxrdbk"
      },
      "source": [
        "result = result.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdqHpFLXrdbm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "17c6ef5f-6267-44c0-df40-5aafbb4e8ed4"
      },
      "source": [
        "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\n",
        "output.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"12311_10\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"8348_2\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"5828_4\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7186_2\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"12128_7\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment\n",
              "0  \"12311_10\"          1\n",
              "1    \"8348_2\"          1\n",
              "2    \"5828_4\"          0\n",
              "3    \"7186_2\"          0\n",
              "4   \"12128_7\"          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTi6zIfaNBez",
        "outputId": "80284f4b-f600-4519-a858-aba2baf3b50e"
      },
      "source": [
        "output_sentiment = output['sentiment'].value_counts()\n",
        "output_sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12689\n",
              "0    12311\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DctvBwHNrdbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8424a22-5517-4643-aa5d-bc081f1b5d0e"
      },
      "source": [
        "print(output_sentiment[0] - output_sentiment[1])\n",
        "output_sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12689\n",
              "0    12311\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FFSbs35rdbn"
      },
      "source": [
        "output.to_csv(\"data/tutorial_4_tfidf_xgboost.csv\", index=False, quoting=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocRs35glrdbr"
      },
      "source": [
        "### Kaggle API를 통해 서브미션이 가능하다.\n",
        "* [Kaggle/kaggle-api: Official Kaggle API](https://github.com/Kaggle/kaggle-api)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mlrf4_Prdbr"
      },
      "source": [
        "# !kaggle competitions submit -c word2vec-nlp-tutorial -f data/tutorial_4_tfidf_xgboost.csv -m 'num_boost_round=300'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5xXVGcZrdbs"
      },
      "source": [
        "# !kaggle competitions submissions -c word2vec-nlp-tutorial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9_ldJ7srdbv"
      },
      "source": [
        "# 캐글 스코어 0.86560\n",
        "286/578"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAHNnL8Wrdbx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}