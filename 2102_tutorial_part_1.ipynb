{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leejungp2/imdb-inflearn/blob/main/2102_tutorial_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhtHElCRZozB"
      },
      "source": [
        "\n",
        "# Bag of Words Meets Bags of Popcorn\n",
        "\n",
        "* https://www.kaggle.com/c/word2vec-nlp-tutorial\n",
        "\n",
        "### [자연 언어 처리 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EC%9E%90%EC%97%B0_%EC%96%B8%EC%96%B4_%EC%B2%98%EB%A6%AC)\n",
        "\n",
        "* 자연 언어 처리(自然言語處理) 또는 자연어 처리(自然語處理)는 인간이 발화하는 언어 현상을 기계적으로 분석해서 컴퓨터가 이해할 수 있는 형태로 만드는 자연 언어 이해 혹은 그러한 형태를 다시 인간이 이해할 수 있는 언어로 표현하는 제반 기술을 의미한다. (출처 : 위키피디아)\n",
        "\n",
        "### 자연어처리(NLP)와 관련 된 캐글 경진대회\n",
        "* [Sentiment Analysis on Movie Reviews | Kaggle](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews)\n",
        "* [Toxic Comment Classification Challenge | Kaggle](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n",
        "* [Spooky Author Identification | Kaggle](https://www.kaggle.com/c/spooky-author-identification)\n",
        "\n",
        "\n",
        "## 튜토리얼 개요\n",
        "### 파트1\n",
        "* 초보자를 대상으로 기본 자연어 처리를 다룬다.\n",
        "\n",
        "### 파트2, 3\n",
        "* Word2Vec을 사용하여 모델을 학습시키는 방법과 감정분석에 단어 벡터를 사용하는 방법을 본다.\n",
        "\n",
        "* 파트3는 레시피를 제공하지 않고 Word2Vec을 사용하는 몇 가지 방법을 실험해 본다.\n",
        "\n",
        "* 파트3에서는 K-means 알고리즘을 사용해 군집화를 해본다.\n",
        "\n",
        "* 긍정과 부정 리뷰가 섞여있는 100,000만개의 IMDB  감정분석 데이터 세트를 통해 목표를 달성해 본다.\n",
        "\n",
        "\n",
        "### 평가 - ROC 커브(Receiver-Operating Characteristic curve)\n",
        "* TPR(True Positive Rate)과 FPR(False Positive Rate)을 각각 x, y 축으로 놓은 그래프\n",
        "* 민감도 TPR\n",
        "    - 1인 케이스에 대해 1로 예측한 비율\n",
        "    - 암환자를 진찰해서 암이라고 진단함\n",
        "* 특이도 FPR\n",
        "    - 0인 케이스에 대해 1로 잘못 예측한 비율\n",
        "    - 암환자가 아닌데 암이라고 진단함\n",
        "    \n",
        "* X, Y가 둘 다 [0, 1] 범위이고 (0, 0)에서 (1, 1)을 잇는 곡선이다.\n",
        "* ROC 커브의 및 면적이 1에 가까울 수록(왼쪽 꼭지점에 다가갈수록) 좋은 성능\n",
        "\n",
        "* 참고 :\n",
        "    * [New Sight :: Roc curve, AUR(AUCOC), 민감도, 특이도](http://newsight.tistory.com/53)\n",
        "    * [ROC의 AUC 구하기 :: 진화하자 - 어디에도 소속되지 않기](http://adnoctum.tistory.com/121)\n",
        "    * [Receiver operating characteristic - Wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
        "    \n",
        "### Use Google's Word2Vec for movie reviews\n",
        "* 자연어 텍스트를 분석해서 특정단어를 얼마나 사용했는지, 얼마나 자주 사용했는지, 어떤 종류의 텍스트인지 분류하거나 긍정인지 부정인지에 대한 감정분석, 그리고 어떤 내용인지 요약하는 정보를 얻을 수 있다.\n",
        "* 감정분석은 머신러닝(기계학습)에서 어려운 주제로 풍자, 애매모호한 말, 반어법, 언어 유희로 표현을 하는데 이는 사람과 컴퓨터에게 모두 오해의 소지가 있다. 여기에서는 Word2Vec을 통한 감정분석을 해보는 튜토리얼을 해본다.\n",
        "* Google의 Word2Vec은 단어의 의미와 관계를 이해하는 데 도움\n",
        "* 상당수의 NLP기능은 nltk모듈에 구현되어 있는데 이 모듈은 코퍼스, 함수와 알고리즘으로 구성되어 있다.\n",
        "* 단어 임베딩 모형 테스트 : [Korean Word2Vec](http://w.elnn.kr/search/)\n",
        "\n",
        "### BOW(bag of words)\n",
        "* 가장 간단하지만 효과적이라 널리쓰이는 방법\n",
        "* 장, 문단, 문장, 서식과 같은 입력 텍스트의 구조를 제외하고 각 단어가 이 말뭉치에 얼마나 많이 나타나는지만 헤아린다.\n",
        "* 구조와 상관없이 단어의 출현횟수만 세기 때문에 텍스트를 담는 가방(bag)으로 생각할 수 있다.\n",
        "* BOW는 단어의 순서가 완전히 무시 된다는 단점이 있다. 예를 들어 의미가 완전히 반대인 두 문장이 있다고 하다.\n",
        "    - `it's bad, not good at all.`\n",
        "    - `it's good, not bad at all.`\n",
        "* 위 두 문장은 의미가 전혀 반대지만 완전히 동일하게 반환된다.\n",
        "* 이를 보완하기 위해 n-gram을 사용하는 데 BOW는 하나의 토큰을 사용하지만 n-gram은 n개의 토큰을 사용할 수 있도록 한다.\n",
        "\n",
        "* [Bag-of-words model - Wikipedia](https://en.wikipedia.org/wiki/Bag-of-words_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMn2bm9FZozC"
      },
      "source": [
        "# 파트 1\n",
        "\n",
        "NLP는?\n",
        "NLP(자연어처리)는 텍스트 문제에 접근하기 위한 기술집합이다.\n",
        "이 튜토리얼에서는 IMDB 영화 리뷰를 로딩하고 정제하고 간단한 BOW(Bag of Words) 모델을 적용하여 리뷰가 추천인지 아닌지에 대한 정확도를 예측한다.\n",
        "\n",
        "\n",
        "### 시작하기 전에\n",
        "이 튜토리얼은 파이썬으로 되어 있으며, NLP에 익숙하다면 파트2 로 건너뛰어도 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpqwoIeSZozD",
        "outputId": "adcdf84b-d8eb-45f9-d090-91696d3134c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\"\"\"\n",
        "header = 0 은 파일의 첫 번째 줄에 열 이름이 있음을 나타내며\n",
        "delimiter = \\t 는 필드가 탭으로 구분되는 것을 의미한다.\n",
        "quoting = 3은 쌍따옴표를 무시하도록 한다.\n",
        "\"\"\"\n",
        "# QUOTE_MINIMAL (0), QUOTE_ALL (1),\n",
        "# QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
        "\n",
        "# 레이블인 sentiment 가 있는 학습 데이터\n",
        "train = pd.read_csv('https://github.com/corazzon/KaggleStruggle/raw/master/word2vec-nlp-tutorial/data/labeledTrainData.tsv', delimiter='\\t', quoting=3)\n",
        "# 레이블이 없는 테스트 데이터\n",
        "test = pd.read_csv('https://github.com/corazzon/KaggleStruggle/raw/master/word2vec-nlp-tutorial/data/testData.tsv', delimiter='\\t', quoting=3)\n",
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdqVdBS4ZozJ",
        "outputId": "c50e3073-f456-4d4b-cd4c-1a566e9a7076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "train.tail(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>\"10905_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"Guy is a loser. Can't get girls, needs to bui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>\"10194_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"This 30 minute documentary Buñuel made in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>\"8478_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"I saw this movie as a child and it broke my h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  sentiment                                             review\n",
              "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
              "24998  \"10194_3\"          0  \"This 30 minute documentary Buñuel made in the...\n",
              "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEhYmyUfZozN",
        "outputId": "09caf712-e5a4-4aaf-bdad-0e14572b6fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BsfkB0tZozQ",
        "outputId": "98ea253b-5553-4ff9-eda6-673cdbcc035a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>\"2155_10\"</td>\n",
              "      <td>\"Sony Pictures Classics, I'm looking at you! S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>\"59_10\"</td>\n",
              "      <td>\"I always felt that Ms. Merkerson had never go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>\"2531_1\"</td>\n",
              "      <td>\"I was so disappointed in this movie. I am ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>\"7772_8\"</td>\n",
              "      <td>\"From the opening sequence, filled with black ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>\"11465_10\"</td>\n",
              "      <td>\"This is a great horror film for people who do...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               id                                             review\n",
              "24995   \"2155_10\"  \"Sony Pictures Classics, I'm looking at you! S...\n",
              "24996     \"59_10\"  \"I always felt that Ms. Merkerson had never go...\n",
              "24997    \"2531_1\"  \"I was so disappointed in this movie. I am ver...\n",
              "24998    \"7772_8\"  \"From the opening sequence, filled with black ...\n",
              "24999  \"11465_10\"  \"This is a great horror film for people who do..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfv30o-5ZozU",
        "outputId": "bde432a2-721f-49a5-d0ba-09ccf98afb04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.columns.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' id', 'sentiment', 'review'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vqy_e0VZozZ",
        "outputId": "28e9e510-1746-4bb1-d6e8-c69a7a5fecf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 레이블인 'sentiment'가 없다. 이 데이터를 기계학습을 통해 예측한다.\n",
        "test.columns.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['id', 'review'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7kidDh7Zozd",
        "outputId": "fe4a2ca4-1852-44ea-b267-25f1503a7605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0    id        25000 non-null  object\n",
            " 1   sentiment  25000 non-null  int64 \n",
            " 2   review     25000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 586.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNUWQH-OZozj",
        "outputId": "236f44bd-4119-4b37-a15f-0ac07e7b8cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>25000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.50001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment\n",
              "count  25000.00000\n",
              "mean       0.50000\n",
              "std        0.50001\n",
              "min        0.00000\n",
              "25%        0.00000\n",
              "50%        0.50000\n",
              "75%        1.00000\n",
              "max        1.00000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7SrlZeiZozn",
        "outputId": "b10bbc34-a781-421f-cb33-95c76c59a666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import numpy as np\n",
        "train.describe(exclude=[np.number])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>25000</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>25000</td>\n",
              "      <td>24904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>\"457_10\"</td>\n",
              "      <td>\"This show comes up with interesting locations...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id                                             review\n",
              "count      25000                                              25000\n",
              "unique     25000                                              24904\n",
              "top     \"457_10\"  \"This show comes up with interesting locations...\n",
              "freq           1                                                  3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9VL-nvKZozq",
        "outputId": "49536583-15c6-4a40-ac2b-0053a1c1fe0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12500\n",
              "0    12500\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXSJxr7fZozy",
        "outputId": "029ac909-a241-4603-efee-f619ebb6ad66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# html 태그가 섞여있기 때문에 이를 정제해줄 필요가 있음\n",
        "train['review'][0][:700]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely lik'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnEPeM1fZoz6"
      },
      "source": [
        "### 데이터 정제 Data Cleaning and Text Preprocessing\n",
        "기계가 텍스트를 이해할 수 있도록 텍스트를 정제해 준다.\n",
        "\n",
        "신호와 소음을 구분한다. 아웃라이어데이터로 인한 오버피팅을 방지한다.\n",
        "\n",
        "1. BeautifulSoup(뷰티풀숩)을 통해 HTML 태그를 제거\n",
        "2. 정규표현식으로 알파벳 이외의 문자를 공백으로 치환\n",
        "3. NLTK 데이터를 사용해 불용어(Stopword)를 제거\n",
        "4. 어간추출(스테밍 Stemming)과 음소표기법(Lemmatizing)의 개념을 이해하고 SnowballStemmer를 통해 어간을 추출\n",
        "\n",
        "\n",
        "### 텍스트 데이터 전처리 이해하기\n",
        "\n",
        "(출처 : [트위터 한국어 형태소 분석기](https://github.com/twitter/twitter-korean-text))\n",
        "\n",
        "**정규화 normalization (입니닼ㅋㅋ -> 입니다 ㅋㅋ, 샤릉해 -> 사랑해)**\n",
        "\n",
        "* 한국어를 처리하는 예시입니닼ㅋㅋㅋㅋㅋ -> 한국어를 처리하는 예시입니다 ㅋㅋ\n",
        "\n",
        "**토큰화 tokenization**\n",
        "\n",
        "* 한국어를 처리하는 예시입니다 ㅋㅋ -> 한국어Noun, 를Josa, 처리Noun, 하는Verb, 예시Noun, 입Adjective, 니다Eomi ㅋㅋKoreanParticle\n",
        "\n",
        "**어근화 stemming (입니다 -> 이다)**\n",
        "\n",
        "* 한국어를 처리하는 예시입니다 ㅋㅋ -> 한국어Noun, 를Josa, 처리Noun, 하다Verb, 예시Noun, 이다Adjective, ㅋㅋKoreanParticle\n",
        "\n",
        "\n",
        "**어구 추출 phrase extraction**\n",
        "\n",
        "* 한국어를 처리하는 예시입니다 ㅋㅋ -> 한국어, 처리, 예시, 처리하는 예시\n",
        "\n",
        "Introductory Presentation: [Google Slides](https://docs.google.com/presentation/d/10CZj8ry03oCk_Jqw879HFELzOLjJZ0EOi4KJbtRSIeU/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onW6--x_Zoz8"
      },
      "source": [
        "* 뷰티풀숩이 설치되지 않았다면 우선 설치해 준다.\n",
        "```\n",
        "!pip install BeautifulSoup4\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUCdFEVzZoz9",
        "outputId": "f97dc09f-9f1b-42bf-f726-655f8f8b976b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# 설치 및 버전확인\n",
        "!pip show BeautifulSoup4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: beautifulsoup4\n",
            "Version: 4.6.3\n",
            "Summary: Screen-scraping library\n",
            "Home-page: http://www.crummy.com/software/BeautifulSoup/bs4/\n",
            "Author: Leonard Richardson\n",
            "Author-email: leonardr@segfault.org\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: \n",
            "Required-by: google, fastai, bs4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilVhhsIKZo0A",
        "outputId": "b59d0df2-0fa2-4f2f-d00f-ac937dda07b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "example1 = BeautifulSoup(train['review'][0], \"html5lib\")\n",
        "print(train['review'][0][:700])\n",
        "example1.get_text()[:700]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely lik\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyw'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp9lER5MZo0J",
        "outputId": "e39a3042-3e83-46f9-df02-a17e55805b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 정규표현식을 사용해서 특수문자를 제거\n",
        "import re\n",
        "# 소문자와 대문자가 아닌 것은 공백으로 대체한다.\n",
        "letters_only = re.sub('[^a-zA-Z]', ' ', example1.get_text())\n",
        "letters_only[:700]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyw'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0yBn_09Zo0N",
        "outputId": "1ac2a5e2-5b56-4820-da7e-cd455de54fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# 모두 소문자로 변환한다.\n",
        "lower_case = letters_only.lower()\n",
        "# 문자를 나눈다. => 토큰화\n",
        "words = lower_case.split()\n",
        "print(len(words))\n",
        "words[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['with',\n",
              " 'all',\n",
              " 'this',\n",
              " 'stuff',\n",
              " 'going',\n",
              " 'down',\n",
              " 'at',\n",
              " 'the',\n",
              " 'moment',\n",
              " 'with']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vi4t6JQZo0S"
      },
      "source": [
        "### 불용어 제거(Stopword Removal)\n",
        "\n",
        "일반적으로 코퍼스에서 자주 나타나는 단어는 학습 모델로서 학습이나 예측 프로세스에 실제로 기여하지 않아 다른 텍스트와 구별하지 못한다. 예를들어 조사, 접미사, i, me, my, it, this, that, is, are 등 과 같은 단어는 빈번하게 등장하지만 실제 의미를 찾는데 큰 기여를 하지 않는다. Stopwords는 \"to\"또는 \"the\"와 같은 용어를 포함하므로 사전 처리 단계에서 제거하는 것이 좋다. NLTK에는 153 개의 영어 불용어가 미리 정의되어 있다. 17개의 언어에 대해 정의되어 있으며 한국어는 없다.\n",
        "\n",
        "\n",
        "### NLTK data 설치\n",
        "* http://corazzon.github.io/nltk_data_install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlGZ1-Upaee7",
        "outputId": "eb2115d1-3a91-4cf0-d202-3888e6321575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tabF2Go9Zo0T",
        "outputId": "b41580ff-f09b-497e-9cf0-711e1503f714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "533xtF8OZo0W",
        "outputId": "ed2edbc7-ed77-4fa6-92bd-c78a03c0c9d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# stopwords 를 제거한 토큰들\n",
        "words = [w for w in words if not w in stopwords.words('english')]\n",
        "print(len(words))\n",
        "words[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stuff',\n",
              " 'going',\n",
              " 'moment',\n",
              " 'mj',\n",
              " 'started',\n",
              " 'listening',\n",
              " 'music',\n",
              " 'watching',\n",
              " 'odd',\n",
              " 'documentary']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6UJduBHZo0Z"
      },
      "source": [
        "### 스테밍(어간추출, 형태소 분석)\n",
        "출처 : [어간 추출 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EC%96%B4%EA%B0%84_%EC%B6%94%EC%B6%9C)\n",
        "\n",
        "\n",
        "* 어간 추출(語幹 抽出, 영어: stemming)은 어형이 변형된 단어로부터 접사 등을 제거하고 그 단어의 어간을 분리해 내는 것\n",
        "* \"message\", \"messages\", \"messaging\" 과 같이 복수형, 진행형 등의 문자를 같은 의미의 단어로 다룰 수 있도록 도와준다.\n",
        "* stemming(형태소 분석): 여기에서는 NLTK에서 제공하는 형태소 분석기를 사용한다. 포터 형태소 분석기는 보수적이고 랭커스터 형태소 분석기는 좀 더 적극적이다. 형태소 분석 규칙의 적극성 때문에 랭커스터 형태소 분석기는 더 많은 동음이의어 형태소를 생산한다. [참고 : 모두의 데이터 과학 with 파이썬(길벗)](http://www.gilbut.co.kr/book/bookView.aspx?bookcode=BN001787)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0RED4oBZo0a",
        "outputId": "8e30c218-b0b5-448b-8f00-accb62437cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 포터 스태머의 사용 예\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "print(stemmer.stem('maximum'))\n",
        "print(\"The stemmed form of running is: {}\".format(stemmer.stem(\"running\")))\n",
        "print(\"The stemmed form of runs is: {}\".format(stemmer.stem(\"runs\")))\n",
        "print(\"The stemmed form of run is: {}\".format(stemmer.stem(\"run\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maximum\n",
            "The stemmed form of running is: run\n",
            "The stemmed form of runs is: run\n",
            "The stemmed form of run is: run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkv6FNWZZo0c",
        "outputId": "b7296ec1-5c65-4ee6-f9b1-d827c44418c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 랭커스터 스태머의 사용 예\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "print(lancaster_stemmer.stem('maximum'))\n",
        "print(\"The stemmed form of running is: {}\".format(lancaster_stemmer.stem(\"running\")))\n",
        "print(\"The stemmed form of runs is: {}\".format(lancaster_stemmer.stem(\"runs\")))\n",
        "print(\"The stemmed form of run is: {}\".format(lancaster_stemmer.stem(\"run\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maxim\n",
            "The stemmed form of running is: run\n",
            "The stemmed form of runs is: run\n",
            "The stemmed form of run is: run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw1HUx48Zo0f",
        "outputId": "e1726ca3-3502-47ef-da9e-26583d74098c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 처리 전 단어\n",
        "words[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stuff',\n",
              " 'going',\n",
              " 'moment',\n",
              " 'mj',\n",
              " 'started',\n",
              " 'listening',\n",
              " 'music',\n",
              " 'watching',\n",
              " 'odd',\n",
              " 'documentary']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocyZ7_HPZo0i",
        "outputId": "139ef843-a85a-45e1-e6fd-d21100a1e719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer('english')\n",
        "words = [stemmer.stem(w) for w in words]\n",
        "# 처리 후 단어\n",
        "words[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stuff',\n",
              " 'go',\n",
              " 'moment',\n",
              " 'mj',\n",
              " 'start',\n",
              " 'listen',\n",
              " 'music',\n",
              " 'watch',\n",
              " 'odd',\n",
              " 'documentari']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5PYWx5CZo0n"
      },
      "source": [
        "### Lemmatization 음소표기법\n",
        "\n",
        "언어학에서 음소 표기법 (또는 lemmatization)은 단어의 보조 정리 또는 사전 형식에 의해 식별되는 단일 항목으로 분석 될 수 있도록 굴절 된 형태의 단어를 그룹화하는 과정이다.\n",
        "예를 들어 동음이의어가 문맥에 따라 다른 의미를 갖는데\n",
        "<pre>\n",
        "1) *배*가 맛있다.\n",
        "2) *배*를 타는 것이 재미있다.\n",
        "3) 평소보다 두 *배*로 많이 먹어서 *배*가 아프다.\n",
        "</pre>\n",
        "위에 있는 3개의 문장에 있는 \"배\"는 모두 다른 의미를 갖는다. <br/>\n",
        "레마타이제이션은 이때 앞뒤 문맥을 보고 단어의 의미를 식별하는 것이다.\n",
        "영어에서 meet는 meeting으로 쓰였을 때 회의를 뜻하지만 meet 일 때는 만나다는 뜻을 갖는데 그 단어가 명사로 쓰였는지 동사로 쓰였는지에 따라 적합한 의미를 갖도록 추출하는 것이다.\n",
        "\n",
        "* 참고 :\n",
        "    - [Stemming and lemmatization](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)\n",
        "    - [Lemmatisation - Wikipedia](https://en.wikipedia.org/wiki/Lemmatisation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9q6wA65Zo0o",
        "outputId": "6a5065f4-e441-487d-d4fd-ecbf3779fe5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(wordnet_lemmatizer.lemmatize('fly'))\n",
        "print(wordnet_lemmatizer.lemmatize('flies'))\n",
        "\n",
        "words = [wordnet_lemmatizer.lemmatize(w) for w in words]\n",
        "# 처리 후 단어\n",
        "words[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fly\n",
            "fly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stuff',\n",
              " 'go',\n",
              " 'moment',\n",
              " 'mj',\n",
              " 'start',\n",
              " 'listen',\n",
              " 'music',\n",
              " 'watch',\n",
              " 'odd',\n",
              " 'documentari']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohd8lSxmZo0r"
      },
      "source": [
        "* 하지만 이 튜토리얼에서는 Stemming과 Lemmatizing을 소개만 해서 stemming 코드를 별도로 추가하였다.\n",
        "\n",
        "\n",
        "# 문자열 처리\n",
        "*  위에서 간략하게 살펴본 내용을 바탕으로 문자열을 처리해 본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rviVKmZaZo0s"
      },
      "source": [
        "def review_to_words( raw_review ):\n",
        "    # 1. HTML 제거\n",
        "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
        "    # 2. 영문자가 아닌 문자는 공백으로 변환\n",
        "    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)\n",
        "    # 3. 소문자 변환\n",
        "    words = letters_only.lower().split()\n",
        "    # 4. 파이썬에서는 리스트보다 세트로 찾는게 훨씬 빠르다.\n",
        "    # stopwords 를 세트로 변환한다.\n",
        "    stops = set(stopwords.words('english'))\n",
        "    # 5. Stopwords 불용어 제거\n",
        "    meaningful_words = [w for w in words if not w in stops]\n",
        "    # 6. 어간추출\n",
        "    stemming_words = [stemmer.stem(w) for w in meaningful_words]\n",
        "    # 7. 공백으로 구분된 문자열로 결합하여 결과를 반환\n",
        "    return( ' '.join(stemming_words) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdcoe8PAbqLC",
        "outputId": "0fdd87c6-e040-4db0-fb9b-1fd9168b71a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4e80b683c395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wordnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Dg3hsSqUZo00",
        "outputId": "9920a7f7-1edb-4344-b097-19299b42924d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "clean_review = review_to_words(train['review'][0])\n",
        "clean_review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2687839b25f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_to_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclean_review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'review_to_words' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZFdl9CZZo03",
        "outputId": "cb4424f7-ccb7-480c-ad62-bced5a508ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 첫 번째 리뷰를 대상으로 전처리 해줬던 내용을 전체 텍스트 데이터를 대상으로 처리한다.\n",
        "# 전체 리뷰 데이터 수 가져오기\n",
        "num_reviews = train['review'].size\n",
        "num_reviews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HMMxHhHZo07",
        "outputId": "ea9ec5f5-eb48-44ff-ae15-b6557c6b3831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "clean_train_reviews = []\n",
        "캐글 튜토리얼에는 range가 xrange로 되어있지만\n",
        "여기에서는 python3를 사용하기 때문에 range를 사용했다.\n",
        "\"\"\"\n",
        "# for i in range(0, num_reviews):\n",
        "#     clean_train_reviews.append( review_to_words(train['review'][i]))\n",
        "\"\"\"\n",
        "하지만 위 코드는 어느 정도 실행이 되고 있는지 알 수가 없어서\n",
        "5000개 단위로 상태를 찍도록 개선했다.\n",
        "\"\"\"\n",
        "# clean_train_reviews = []\n",
        "# for i in range(0, num_reviews):\n",
        "#     if (i + 1)%5000 == 0:\n",
        "#         print('Review {} of {} '.format(i+1, num_reviews))\n",
        "#     clean_train_reviews.append(review_to_words(train['review'][i]))\n",
        "\n",
        "\"\"\"\n",
        "그리고 코드를 좀 더 간결하게 하기 위해 for loop를 사용하는\n",
        "대신 apply를 사용하도록 개선\n",
        "\"\"\"\n",
        "# %time train['review_clean'] = train['review'].apply(review_to_words)\n",
        "\"\"\"\n",
        "코드는 한 줄로 간결해 졌지만 여전히 오래 걸림\n",
        "\"\"\"\n",
        "# CPU times: user 1min 15s, sys: 2.3 s, total: 1min 18s\n",
        "# Wall time: 1min 20s\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n코드는 한 줄로 간결해 졌지만 여전히 오래 걸림\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOjdG-_cZo1C"
      },
      "source": [
        "# 참고 : https://gist.github.com/yong27/7869662\n",
        "# http://www.racketracer.com/2016/07/06/pandas-in-parallel/\n",
        "from multiprocessing import Pool\n",
        "import numpy as np\n",
        "\n",
        "def _apply_df(args):\n",
        "    df, func, kwargs = args\n",
        "    return df.apply(func, **kwargs)\n",
        "\n",
        "def apply_by_multiprocessing(df, func, **kwargs):\n",
        "    # 키워드 항목 중 workers 파라메터를 꺼냄\n",
        "    workers = kwargs.pop('workers')\n",
        "    # 위에서 가져온 workers 수로 프로세스 풀을 정의\n",
        "    pool = Pool(processes=workers)\n",
        "    # 실행할 함수와 데이터프레임을 워커의 수 만큼 나눠 작업\n",
        "    result = pool.map(_apply_df, [(d, func, kwargs)\n",
        "            for d in np.array_split(df, workers)])\n",
        "    pool.close()\n",
        "    # 작업 결과를 합쳐서 반환\n",
        "    return pd.concat(list(result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr6g6WvJbKOq",
        "outputId": "fbbc959e-90c7-40de-9577-1d4061f1e46b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw44mjOEZo1D",
        "outputId": "7e802ad8-c71f-4c6f-cee0-45b495afa0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time clean_train_reviews = apply_by_multiprocessing(\\\n",
        "    train['review'], review_to_words, workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 105 ms, sys: 129 ms, total: 234 ms\n",
            "Wall time: 44.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvbpZ8_sZo1G",
        "outputId": "621494c7-5968-4ab5-eabc-acbfbca22810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time clean_test_reviews = apply_by_multiprocessing(\\\n",
        "    test['review'], review_to_words, workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 104 ms, sys: 120 ms, total: 224 ms\n",
            "Wall time: 43.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHEMsPT1Zo1L"
      },
      "source": [
        "### 워드 클라우드\n",
        "- 단어의 빈도 수 데이터를 가지고 있을 때 이용할 수 있는 시각화 방법\n",
        "- 단순히 빈도 수를 표현하기 보다는 상관관계나 유사도 등으로 배치하는 게 더 의미 있기 때문에 큰 정보를 얻기는 어렵다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-CaN5AuZo1M"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline 설정을 해주어야지만 노트북 안에 그래프가 디스플레이 된다.\n",
        "%matplotlib inline\n",
        "\n",
        "def displayWordCloud(data = None, backgroundcolor = 'white', width=800, height=600 ):\n",
        "    wordcloud = WordCloud(stopwords = STOPWORDS,\n",
        "                          background_color = backgroundcolor,\n",
        "                         width = width, height = height).generate(data)\n",
        "    plt.figure(figsize = (15 , 10))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRDryojgZo1X",
        "outputId": "a292332a-8f30-49c0-8c8b-f5cbdc9a3aff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "# 학습 데이터의 모든 단어에 대한 워드 클라우드를 그려본다.\n",
        "%time displayWordCloud(' '.join(clean_train_reviews))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3a0944b5eb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습 데이터의 모든 단어에 대한 워드 클라우드를 그려본다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time displayWordCloud(' '.join(clean_train_reviews))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clean_train_reviews' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-_XplaSZo1d"
      },
      "source": [
        "# 단어 수\n",
        "train['num_words'] = clean_train_reviews.apply(lambda x: len(str(x).split()))\n",
        "# 중복을 제거한 단어 수\n",
        "train['num_uniq_words'] = clean_train_reviews.apply(lambda x: len(set(str(x).split())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2t3rYHnZo1a"
      },
      "source": [
        "# 테스트 데이터의 모든 단어에 대한 워드 클라우드를 그려본다.\n",
        "%time displayWordCloud(' '.join(clean_test_reviews))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftEYida3Zo1g"
      },
      "source": [
        "# 첫 번째 리뷰에\n",
        "x = clean_train_reviews[0]\n",
        "x = str(x).split()\n",
        "print(len(x))\n",
        "x[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLw0qoqrZo1n"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2)\n",
        "fig.set_size_inches(18, 6)\n",
        "print('리뷰별 단어 평균 값 :', train['num_words'].mean())\n",
        "print('리뷰별 단어 중간 값', train['num_words'].median())\n",
        "sns.distplot(train['num_words'], bins=100, ax=axes[0])\n",
        "axes[0].axvline(train['num_words'].median(), linestyle='dashed')\n",
        "axes[0].set_title('review unique word distribution')\n",
        "\n",
        "print('review unique word mean :', train['num_uniq_words'].mean())\n",
        "print('review unique word median', train['num_uniq_words'].median())\n",
        "sns.distplot(train['num_uniq_words'], bins=100, color='g', ax=axes[1])\n",
        "axes[1].axvline(train['num_uniq_words'].median(), linestyle='dashed')\n",
        "axes[1].set_title('review unique word distribution')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbPeMqPHZo1p"
      },
      "source": [
        "### [Bag-of-words model - Wikipedia](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
        "\n",
        "다음의 두 문장이 있다고 하자,\n",
        "```\n",
        "(1) John likes to watch movies. Mary likes movies too.\n",
        "(2) John also likes to watch football games.\n",
        "```\n",
        "위 두 문장을 토큰화 하여 가방에 담아주면 다음과 같다.\n",
        "\n",
        "```\n",
        "[\n",
        "    \"John\",\n",
        "    \"likes\",\n",
        "    \"to\",\n",
        "    \"watch\",\n",
        "    \"movies\",\n",
        "    \"Mary\",\n",
        "    \"too\",\n",
        "    \"also\",\n",
        "    \"football\",\n",
        "    \"games\"\n",
        "]\n",
        "```\n",
        "\n",
        "그리고 배열의 순서대로 가방에서 각 토큰이 몇 번 등장하는지 횟수를 세어준다.\n",
        "```\n",
        "(1) [1, 2, 1, 1, 2, 1, 1, 0, 0, 0]\n",
        "(2) [1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
        "```\n",
        "=> 머신러닝 알고리즘이 이해할 수 있는 형태로 바꿔주는 작업이다.\n",
        "\n",
        "단어 가방을 n-gram을 사용해 bigram 으로 담아주면 다음과 같다.\n",
        "```\n",
        "[\n",
        "    \"John likes\",\n",
        "    \"likes to\",\n",
        "    \"to watch\",\n",
        "    \"watch movies\",\n",
        "    \"Mary likes\",\n",
        "    \"likes movies\",\n",
        "    \"movies too\",\n",
        "]\n",
        "```\n",
        "=> 여기에서는 CountVectorizer를 통해 위 작업을 한다.\n",
        "\n",
        "\n",
        "### 사이킷런의 CountVectorizer를 통해 피처 생성\n",
        "* 정규표현식을 사용해 토큰을 추출한다.\n",
        "* 모두 소문자로 변환시키기 때문에 good, Good, gOod이 모두 같은 특성이 된다.\n",
        "* 의미없는 특성을 많이 생성하기 때문에 적어도 두 개의 문서에 나타난 토큰만을 사용한다.\n",
        "* min_df로 토큰이 나타날 최소 문서 개수를 지정할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDmkThnHZo1p",
        "outputId": "64ebe09a-bda0-4084-ed26-8c6b0173f235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 튜토리얼과 다르게 파라메터 값을 수정\n",
        "# 파라메터 값만 수정해도 캐글 스코어 차이가 많이 남\n",
        "vectorizer = CountVectorizer(analyzer = 'word',\n",
        "                             tokenizer = None,\n",
        "                             preprocessor = None,\n",
        "                             stop_words = None,\n",
        "                             min_df = 2, # 토큰이 나타날 최소 문서 개수\n",
        "                             ngram_range=(1, 3),\n",
        "                             max_features = 20000\n",
        "                            )\n",
        "vectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=20000, min_df=2,\n",
              "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdkFJ9j7Zo1s"
      },
      "source": [
        "# 속도 개선을 위해 파이프라인을 사용하도록 개선\n",
        "# 참고 : https://stackoverflow.com/questions/28160335/plot-a-document-tfidf-2d-graph\n",
        "pipeline = Pipeline([\n",
        "    ('vect', vectorizer),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SVTVLiCZo1u",
        "outputId": "5fe272d9-f3f5-434b-b905-fd0e368507be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%time train_data_features = pipeline.fit_transform(clean_train_reviews)\n",
        "train_data_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 28.2 s, sys: 563 ms, total: 28.7 s\n",
            "Wall time: 28.8 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<25000x20000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 2762268 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AZXuESTZo1w"
      },
      "source": [
        "* 보통 fit을 학습하는데 사용하는데 여기에서는 벡터화 할 때도 fit을 사용했습니다. 사이킷런에 구현된 벡터화 알고리즘이 fit을 사용해서 벡터화 하도록 되어 있습니다. 따라서 RF에서의 fit과 벡터화에 사용되는 fit은 다른 성격입니다.\n",
        "\n",
        "##  pipeline\n",
        "* 영상에 성능을 위해 pipeline을 사용했다는 말이 있는데 이 부분을 정정합니다.\n",
        "* 아래의 공식 문서를 보면 pipeline 에서 메모리의 캐시를 사용할 수 있다는 문구도 있습니다. 하지만 성능상의 이슈라기보다는 cross-validation 과 GridSearch 과정을 하나로 만들어 주는게 pipeline의 가장 큰 장점이라고 합니다. 저는 하나의 과정만 묶어줘서 사실 굳이 pipeline을 쓸 필요는 없는데 보통 transform 하는 과정에서 pipeline을 사용합니다.\n",
        "\n",
        "\n",
        "* 제 코드에는 cross-validation 과 GridSearch 과정이 없는데 해당 과정은 모델의 성능(정확도)를 측정해 보는 과정이고, GridSearch는 최적의 하이퍼파라메터를 찾는 과정입니다.\n",
        "\n",
        "* Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using memory argument.\n",
        "\n",
        "\n",
        "* 더 읽어보기 : https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk34jea4Zo1w",
        "outputId": "150b66a9-6498-4a61-d45d-6cb61cc968d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 20000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYdzv5p0Zo12",
        "outputId": "78a85e5d-9bfa-4128-f018-8806e0a1b54a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab = vectorizer.get_feature_names()\n",
        "print(len(vocab))\n",
        "vocab[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aag',\n",
              " 'aaron',\n",
              " 'ab',\n",
              " 'abandon',\n",
              " 'abbey',\n",
              " 'abbi',\n",
              " 'abbot',\n",
              " 'abbott',\n",
              " 'abc',\n",
              " 'abduct']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JklB2fU2Zo14",
        "outputId": "10ec7a3b-e264-43bd-8787-890ab206383b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 벡터화 된 피처를 확인해 봄\n",
        "import numpy as np\n",
        "dist = np.sum(train_data_features, axis=0)\n",
        "\n",
        "for tag, count in zip(vocab, dist):\n",
        "    print(count, tag)\n",
        "\n",
        "pd.DataFrame(dist, columns=vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[26 48 22 ... 59 40 23]] aag\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aag</th>\n",
              "      <th>aaron</th>\n",
              "      <th>ab</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abbey</th>\n",
              "      <th>abbi</th>\n",
              "      <th>abbot</th>\n",
              "      <th>abbott</th>\n",
              "      <th>abc</th>\n",
              "      <th>abduct</th>\n",
              "      <th>abe</th>\n",
              "      <th>abhay</th>\n",
              "      <th>abid</th>\n",
              "      <th>abigail</th>\n",
              "      <th>abil</th>\n",
              "      <th>abil make</th>\n",
              "      <th>abl</th>\n",
              "      <th>abl get</th>\n",
              "      <th>abl make</th>\n",
              "      <th>abl see</th>\n",
              "      <th>abl watch</th>\n",
              "      <th>abli</th>\n",
              "      <th>aboard</th>\n",
              "      <th>abomin</th>\n",
              "      <th>aborigin</th>\n",
              "      <th>abort</th>\n",
              "      <th>abound</th>\n",
              "      <th>abraham</th>\n",
              "      <th>abraham lincoln</th>\n",
              "      <th>abroad</th>\n",
              "      <th>abrupt</th>\n",
              "      <th>absenc</th>\n",
              "      <th>absent</th>\n",
              "      <th>absolut</th>\n",
              "      <th>absolut aw</th>\n",
              "      <th>absolut brilliant</th>\n",
              "      <th>absolut hilari</th>\n",
              "      <th>absolut horribl</th>\n",
              "      <th>absolut love</th>\n",
              "      <th>absolut noth</th>\n",
              "      <th>...</th>\n",
              "      <th>yuen</th>\n",
              "      <th>yugoslavia</th>\n",
              "      <th>yup</th>\n",
              "      <th>yuppi</th>\n",
              "      <th>yuzna</th>\n",
              "      <th>yvonn</th>\n",
              "      <th>zabriski</th>\n",
              "      <th>zabriski point</th>\n",
              "      <th>zach</th>\n",
              "      <th>zack</th>\n",
              "      <th>zane</th>\n",
              "      <th>zani</th>\n",
              "      <th>zatoichi</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zelah</th>\n",
              "      <th>zelah clark</th>\n",
              "      <th>zelda</th>\n",
              "      <th>zenia</th>\n",
              "      <th>zero</th>\n",
              "      <th>zero day</th>\n",
              "      <th>zero star</th>\n",
              "      <th>zeta</th>\n",
              "      <th>zeta jone</th>\n",
              "      <th>zhang</th>\n",
              "      <th>zip</th>\n",
              "      <th>zizek</th>\n",
              "      <th>zodiac</th>\n",
              "      <th>zodiac killer</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zombi</th>\n",
              "      <th>zombi bloodbath</th>\n",
              "      <th>zombi film</th>\n",
              "      <th>zombi flick</th>\n",
              "      <th>zombi movi</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26</td>\n",
              "      <td>48</td>\n",
              "      <td>22</td>\n",
              "      <td>288</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>125</td>\n",
              "      <td>55</td>\n",
              "      <td>24</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>562</td>\n",
              "      <td>25</td>\n",
              "      <td>1259</td>\n",
              "      <td>53</td>\n",
              "      <td>32</td>\n",
              "      <td>54</td>\n",
              "      <td>35</td>\n",
              "      <td>27</td>\n",
              "      <td>37</td>\n",
              "      <td>83</td>\n",
              "      <td>69</td>\n",
              "      <td>92</td>\n",
              "      <td>63</td>\n",
              "      <td>93</td>\n",
              "      <td>29</td>\n",
              "      <td>38</td>\n",
              "      <td>136</td>\n",
              "      <td>118</td>\n",
              "      <td>83</td>\n",
              "      <td>1850</td>\n",
              "      <td>29</td>\n",
              "      <td>35</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>93</td>\n",
              "      <td>154</td>\n",
              "      <td>...</td>\n",
              "      <td>21</td>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>32</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>40</td>\n",
              "      <td>36</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>70</td>\n",
              "      <td>38</td>\n",
              "      <td>33</td>\n",
              "      <td>47</td>\n",
              "      <td>43</td>\n",
              "      <td>34</td>\n",
              "      <td>28</td>\n",
              "      <td>31</td>\n",
              "      <td>390</td>\n",
              "      <td>44</td>\n",
              "      <td>32</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>23</td>\n",
              "      <td>85</td>\n",
              "      <td>45</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>1331</td>\n",
              "      <td>23</td>\n",
              "      <td>52</td>\n",
              "      <td>37</td>\n",
              "      <td>89</td>\n",
              "      <td>161</td>\n",
              "      <td>31</td>\n",
              "      <td>71</td>\n",
              "      <td>59</td>\n",
              "      <td>40</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 20000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aag  aaron  ab  abandon  abbey  abbi  ...  zone  zoo  zoom  zorro  zu  zucker\n",
              "0   26     48  22      288     24    30  ...   161   31    71     59  40      23\n",
              "\n",
              "[1 rows x 20000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj-0-oRbZo19",
        "outputId": "03f4e327-7a21-4c12-b3f4-89f84ba88b0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pd.DataFrame(train_data_features[:10].toarray(), columns=vocab).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aag</th>\n",
              "      <th>aaron</th>\n",
              "      <th>ab</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abbey</th>\n",
              "      <th>abbi</th>\n",
              "      <th>abbot</th>\n",
              "      <th>abbott</th>\n",
              "      <th>abc</th>\n",
              "      <th>abduct</th>\n",
              "      <th>abe</th>\n",
              "      <th>abhay</th>\n",
              "      <th>abid</th>\n",
              "      <th>abigail</th>\n",
              "      <th>abil</th>\n",
              "      <th>abil make</th>\n",
              "      <th>abl</th>\n",
              "      <th>abl get</th>\n",
              "      <th>abl make</th>\n",
              "      <th>abl see</th>\n",
              "      <th>abl watch</th>\n",
              "      <th>abli</th>\n",
              "      <th>aboard</th>\n",
              "      <th>abomin</th>\n",
              "      <th>aborigin</th>\n",
              "      <th>abort</th>\n",
              "      <th>abound</th>\n",
              "      <th>abraham</th>\n",
              "      <th>abraham lincoln</th>\n",
              "      <th>abroad</th>\n",
              "      <th>abrupt</th>\n",
              "      <th>absenc</th>\n",
              "      <th>absent</th>\n",
              "      <th>absolut</th>\n",
              "      <th>absolut aw</th>\n",
              "      <th>absolut brilliant</th>\n",
              "      <th>absolut hilari</th>\n",
              "      <th>absolut horribl</th>\n",
              "      <th>absolut love</th>\n",
              "      <th>absolut noth</th>\n",
              "      <th>...</th>\n",
              "      <th>yuen</th>\n",
              "      <th>yugoslavia</th>\n",
              "      <th>yup</th>\n",
              "      <th>yuppi</th>\n",
              "      <th>yuzna</th>\n",
              "      <th>yvonn</th>\n",
              "      <th>zabriski</th>\n",
              "      <th>zabriski point</th>\n",
              "      <th>zach</th>\n",
              "      <th>zack</th>\n",
              "      <th>zane</th>\n",
              "      <th>zani</th>\n",
              "      <th>zatoichi</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zelah</th>\n",
              "      <th>zelah clark</th>\n",
              "      <th>zelda</th>\n",
              "      <th>zenia</th>\n",
              "      <th>zero</th>\n",
              "      <th>zero day</th>\n",
              "      <th>zero star</th>\n",
              "      <th>zeta</th>\n",
              "      <th>zeta jone</th>\n",
              "      <th>zhang</th>\n",
              "      <th>zip</th>\n",
              "      <th>zizek</th>\n",
              "      <th>zodiac</th>\n",
              "      <th>zodiac killer</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zombi</th>\n",
              "      <th>zombi bloodbath</th>\n",
              "      <th>zombi film</th>\n",
              "      <th>zombi flick</th>\n",
              "      <th>zombi movi</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zu</th>\n",
              "      <th>zucker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 20000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aag  aaron  ab  abandon  abbey  abbi  ...  zone  zoo  zoom  zorro  zu  zucker\n",
              "0    0      0   0        0      0     0  ...     0    0     0      0   0       0\n",
              "1    0      0   0        0      0     0  ...     0    0     0      0   0       0\n",
              "2    0      0   0        0      0     0  ...     0    0     0      0   0       0\n",
              "3    0      0   0        0      0     0  ...     0    0     0      0   0       0\n",
              "4    0      0   0        0      0     0  ...     0    0     0      0   0       0\n",
              "\n",
              "[5 rows x 20000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15rI8o7oZo2A"
      },
      "source": [
        "### [랜덤 포레스트 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EB%9E%9C%EB%8D%A4_%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8)\n",
        "랜덤 포레스트의 가장 핵심적인 특징은 임의성(randomness)에 의해 서로 조금씩 다른 특성을 갖는 트리들로 구성된다는 점이다. 이 특징은 각 트리들의 예측(prediction)들이 비상관화(decorrelation) 되게하며, 결과적으로 일반화(generalization) 성능을 향상시킨다. 또한, 임의화(randomization)는 포레스트가 노이즈가 포함된 데이터에 대해서도 강하게 만들어 준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckuKcvu0Zo2A",
        "outputId": "1569471e-8886-4cd1-e83f-8c7f6e806516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 랜덤포레스트 분류기를 사용\n",
        "forest = RandomForestClassifier(\n",
        "    n_estimators = 100, n_jobs = -1, random_state=2018)\n",
        "forest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=2018, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyrohn_bZo2D",
        "outputId": "311d03e4-52ca-4e6a-ae7e-604012adc5ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%time forest = forest.fit(train_data_features, train['sentiment'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 18s, sys: 59 ms, total: 1min 18s\n",
            "Wall time: 40 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU0rTIoaZo2F",
        "outputId": "4821c925-50bb-4b2d-f631-791e839c07b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "%time score = np.mean(cross_val_score(\\\n",
        "    forest, train_data_features, \\\n",
        "    train['sentiment'], cv=10, scoring='roc_auc'))\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.73 s, sys: 784 ms, total: 8.51 s\n",
            "Wall time: 5min 57s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92761104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5uIxsoiZo2I"
      },
      "source": [
        "## 캐글 스코어와 CV 결과가 다른 이유\n",
        "\n",
        "* cross validation은 train 데이터로 점수를 낸것이고, 캐글은 test 데이터로 점수를 구한거라 결과가 다릅니다.\n",
        "\n",
        "```\n",
        "시험공부에 비유해 보면,\n",
        "1) 기출문제를 모은다 (feature engineering)\n",
        "2) 공부한다 (model.fit)\n",
        "3) 시험본다 (predict)\n",
        "```\n",
        "\n",
        "* 여기에서 2번 단계를 하는 여러 전략이 있을텐데요, 기출문제를 모두 외워버리면 과연 내가 실제 시험을 잘 치룰 수 있을지 아니면 공부를 더 해야할지 판단하기가 애매합니다.\n",
        "* 괜찮은 전략 중 하나는 기출문제 중 일부를 임의로 뽑아내서 공부하고(training set을 이용한 학습),\n",
        "* 나머지 기출문제를 풀어보며 내가 얼마나 잘 푸는지 평가를 해보는겁니다(validation set을 통해 학습의 성과를 검증).\n",
        "* 잘 된다 싶으면 시험을 볼 준비가 된 것입니다(실전 투입).\n",
        "\n",
        "* 기출문제를 몽땅 외우면 기출문제 내에서는 100점을 받겠지만(overfitting), 실전에서도 그러한 성적을 가두리라 기대하기 어렵습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF6wDEDFZo2I"
      },
      "source": [
        "# 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpo5sS6BZo2J",
        "outputId": "6e964af7-6d53-447d-feb1-0998be69a83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 위에서 정제해준 리뷰의 첫 번째 데이터를 확인\n",
        "clean_test_reviews[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natur film main theme mortal nostalgia loss innoc perhap surpris rate high older viewer younger one howev craftsmanship complet film anyon enjoy pace steadi constant charact full engag relationship interact natur show need flood tear show emot scream show fear shout show disput violenc show anger natur joyc short stori lend film readi made structur perfect polish diamond small chang huston make inclus poem fit neat truli masterpiec tact subtleti overwhelm beauti'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVq3ZGnyZo2L",
        "outputId": "3d9c8016-28b5-4779-827b-05f28b0e2afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 테스트 데이터를 벡터화 함\n",
        "%time test_data_features = pipeline.transform(clean_test_reviews)\n",
        "test_data_features = test_data_features.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.21 s, sys: 17.1 ms, total: 6.23 s\n",
            "Wall time: 6.24 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nbsmvXIZo2N",
        "outputId": "7e27fb4b-15c3-4543-c293-385f434c9c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "test_data_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNJfTQewZo2P",
        "outputId": "268fae58-e792-4300-c8d7-e07dec8f660b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# 벡터화 된 단어로 숫자가 문서에서 등장하는 횟수를 나타낸다\n",
        "test_data_features[5][:100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j68t2L-HZo2T",
        "outputId": "6e21b4e8-9c2b-4caa-c55a-1c5cb7848062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 벡터화 하며 만든 사전에서 해당 단어가 무엇인지 찾아볼 수 있다.\n",
        "# vocab = vectorizer.get_feature_names()\n",
        "vocab[8], vocab[2558], vocab[2559], vocab[2560]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('abc', 'charact person', 'charact play', 'charact plot')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P38rsVRZo2U",
        "outputId": "3f05bd8a-eb18-41c4-b042-dda5d75af7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 테스트 데이터를 넣고 예측한다.\n",
        "result = forest.predict(test_data_features)\n",
        "result[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 1, 0, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-BP5Zf1Zo2W"
      },
      "source": [
        "# 캐글 제출을 위해 예측결과 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXDD4S-zZo2X",
        "outputId": "ce90b1ee-f948-4e34-97c8-008df593ce7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# 예측 결과를 저장하기 위해 데이터프레임에 담아 준다.\n",
        "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\n",
        "output.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"12311_10\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"8348_2\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"5828_4\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7186_2\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"12128_7\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment\n",
              "0  \"12311_10\"          1\n",
              "1    \"8348_2\"          0\n",
              "2    \"5828_4\"          0\n",
              "3    \"7186_2\"          1\n",
              "4   \"12128_7\"          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8t9MhSNZo2c"
      },
      "source": [
        "output.to_csv('tutorial_1_BOW_{0:.5f}.csv'.format(score), index=False, quoting=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrT0KO0bZo2f",
        "outputId": "7ff017ba-1509-4758-96b1-055f150b075d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "output_sentiment = output['sentiment'].value_counts()\n",
        "print(np.abs(output_sentiment[0] - output_sentiment[1]))\n",
        "output_sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    12554\n",
              "1    12446\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIbJj9-TZo2j"
      },
      "source": [
        "## Train, Test의 감정분류 결과 값 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBbWdHxsZo2k",
        "outputId": "353df960-3419-49ed-9226-01c3d6e865f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fig, axes = plt.subplots(ncols=2)\n",
        "fig.set_size_inches(12,5)\n",
        "sns.countplot(train['sentiment'], ax=axes[0])\n",
        "sns.countplot(output['sentiment'], ax=axes[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f20a3ea4518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAE9CAYAAABKltdlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAwkgAMAwEACOAAADPT/AYoIV4DlxV7AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xqy2ZAQZo2o"
      },
      "source": [
        "첫 번째 제출을 할 준비가 되었다.\n",
        "리뷰를 다르게 정리하거나 'Bag of Words' 표현을 위해 다른 수의 어휘 단어를 선택하거나 포터 스테밍 등을 시도해 볼 수 있다.\n",
        "다른 데이터세트로 NLP를 시도해 보려면 로튼 토마토(Rotten Tomatoes)를 해보는 것도 좋다.\n",
        "\n",
        "* 로튼 토마토 데이터 셋을 사용하는 경진대회 : [Sentiment Analysis on Movie Reviews | Kaggle](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq-RR_JFZo2p"
      },
      "source": [
        "## 캐글 제출 결과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J85vP0pBZo2q",
        "outputId": "05b9bfb6-98fc-47a0-f93d-2cd5fe8cf380",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 파라메터를 조정해 가며 점수를 조금씩 올려본다.\n",
        "\n",
        "# uni-gram 사용 시 캐글 점수 0.84476\n",
        "print(436/578)\n",
        "# tri-gram 사용 시 캐글 점수 0.84608\n",
        "print(388/578)\n",
        "# 어간추출 후 캐글 점수 0.84780\n",
        "print(339/578)\n",
        "# 랜덤포레스트의 max_depth = 5 로 지정하고\n",
        "# CountVectorizer의 tokenizer=nltk.word_tokenize 를 지정 후 캐글 점수 0.81460\n",
        "print(546/578)\n",
        "# 랜덤포레스트의 max_depth = 5 는 다시 None으로 변경\n",
        "# CountVectorizer max_features = 10000개로 변경 후 캐글 점수 0.85272\n",
        "print(321/578)\n",
        "# CountVectorizer의 tokenizer=nltk.word_tokenize 를 지정 후 캐글 점수 0.85044\n",
        "print(326/578)\n",
        "# CountVectorizer max_features = 10000개로 변경 후 캐글 점수 0.85612\n",
        "print(305/578)\n",
        "# 0.85884\n",
        "print(296/578)\n",
        "\n",
        "print(310/578)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.754325259515571\n",
            "0.671280276816609\n",
            "0.5865051903114187\n",
            "0.9446366782006921\n",
            "0.5553633217993079\n",
            "0.5640138408304498\n",
            "0.527681660899654\n",
            "0.5121107266435986\n",
            "0.5363321799307958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9v1L5fJZo2u"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}